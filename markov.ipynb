{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markovify in /Users/maxfowler/opt/anaconda3/lib/python3.7/site-packages (0.8.2)\r\n",
      "Requirement already satisfied: unidecode in /Users/maxfowler/opt/anaconda3/lib/python3.7/site-packages (from markovify) (1.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "# installing markovify\n",
    "!conda install -c conda-forge markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everyone at the combin\n",
      "100 likes and ill pull the fire alarm at the bushwick art gallery im at the bedford nostrand G stop\n",
      "if trish keenan was still alive she would save us from net art is basically like a century ago when everyone in my office wants to hang ill be overdressed and sweating at the basement noise scene you were the man homie\n",
      "hey guys i think im weird\n",
      "i want to kill themselves\n"
     ]
    }
   ],
   "source": [
    "# simple markov\n",
    "import markovify\n",
    "\n",
    "# Get raw text as string.\n",
    "with open(\"/Users/maxfowler/Desktop/texts/versace.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Build the model \n",
    "# (we are  using markovify.NewlineText instead of markovify.Text \n",
    "# because the source text doesn't have many periods, and NewlineText treats \"newlines\" as new sentences\n",
    "text_model = markovify.NewlineText(text)\n",
    "    \n",
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    sentence = text_model.make_sentence()\n",
    "    # we exclude any sentences that have an @ symbol in it, as a way of excluding tweets with a mention \n",
    "    # (this was just a preference for what seemed to make more interesting results)\n",
    "    if not \"@\" in sentence:\n",
    "        print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penguin rear its young, the Emperor mainly consists of fish and crustaceans. There\n",
      "penguin has adapted itself to the fasting birds\n",
      "penguin returned to their charge. They squabble continually with their flippers with the Antarctic night.\n",
      "penguin rear its young, the Emperor is white, pyriform in shape, and weighs just\n",
      "penguin to get food, and at the top of Cape\n"
     ]
    }
   ],
   "source": [
    "# with_start\n",
    "import markovify\n",
    "\n",
    "# Get raw text as string.\n",
    "with open(\"/Users/maxfowler/Desktop/texts/antarctic-penguins.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Build the model.\n",
    "text_model = markovify.NewlineText(text)\n",
    "    \n",
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    sentence = text_model.make_sentence_with_start(beginning=\"penguin\", strict=False)\n",
    "    if not \"@\" in sentence:\n",
    "        print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maybe all conversation would be people who kill what they can't understand\n",
      "In one of these birds should avoid the snow-banks, unable to identify universal vs regional trends e.g trash bags under sink\n",
      "going to listen to a point to point at cars in other lane still driving i would do a 20 year study to see him leaping about on the slopes and\n",
      "formerly abundant along eastern base of foothills to the thrushes\n",
      "shallow runway. I trudged down the back of the mountain among\n"
     ]
    }
   ],
   "source": [
    "# combining models\n",
    "import markovify\n",
    "\n",
    "patha = \"/Users/maxfowler/Desktop/texts/notplants.txt\"\n",
    "pathb = \"/Users/maxfowler/Desktop/texts/birds-of-rockies.txt\"\n",
    "\n",
    "# open both of the files, and read the text into variables \n",
    "with open(patha) as fa:\n",
    "    text_a = fa.read()\n",
    "    \n",
    "with open(pathb) as fb:\n",
    "    text_b = fb.read()\n",
    "\n",
    "# Build the models. \n",
    "model_a = markovify.NewlineText(text_a)\n",
    "model_b = markovify.NewlineText(text_b)\n",
    "\n",
    "# combine the models together, setting the weights of how much to favor which source text\n",
    "weight_a = 1\n",
    "weight_b = 0.2\n",
    "model_combo = markovify.combine([ model_a, model_b ], [ weight_a, weight_b ])\n",
    "    \n",
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    sentence = model_combo.make_sentence()\n",
    "    # (still excluding sentences with @)\n",
    "    if not \"@\" in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would like me to do though. Let me know if you | you pass on the morning of October 16 at 11 A.M. there were skuas about, but when this subsided,\n",
      "\n",
      "\n",
      "In addition, it includes a year to | to depart. Many others, however, still wandered disconsolately about the surface as he got into the water. The height of some of whom could be secured, it seemed to be fed and\n",
      "\n",
      "\n",
      "Intruders can use the vulnerabilities exploited by this worm are being used to scan and | and ice-foot in company for some hours, spreading\n",
      "\n",
      "\n",
      "is the latest with the billy club? That's how my | my photographs, in which many of them, indeed, seemed to be killed or severely\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is a more complex example of concatenating markov chains together\n",
    "# so a sentence starts out sounding like one model, and halfway through starts sounding like another\n",
    "# this is meant to show its possible to play around and customize as desired \n",
    "import markovify\n",
    "\n",
    "patha = \"/Users/maxfowler/Desktop/texts/enron.txt\"\n",
    "pathb = \"/Users/maxfowler/Desktop/texts/antarctic-penguins.txt\"\n",
    "\n",
    "# open both of the files, and read the text into variables \n",
    "with open(patha) as fa:\n",
    "    text_a = fa.read()\n",
    "    \n",
    "with open(pathb) as fb:\n",
    "    text_b = fb.read()\n",
    "\n",
    "# Build the models\n",
    "model_a = markovify.NewlineText(text_a)\n",
    "model_b = markovify.NewlineText(text_b)\n",
    "    \n",
    "generated = 0\n",
    "num_to_print = 3\n",
    "# Print five randomly-generated sentences\n",
    "# we use a counter, because we are going to exclude some sentences \n",
    "for i in range(100):\n",
    "    sentence_a = model_a.make_sentence()\n",
    "    if not sentence_a:\n",
    "        continue\n",
    "    a_words = sentence_a.split(' ')\n",
    "    sentence_b = model_b.make_sentence_with_start(beginning=a_words[-1], strict=False)\n",
    "    if sentence_a and sentence_b:\n",
    "        generated += 1\n",
    "        full_sentence = sentence_a + ' | ' + sentence_b\n",
    "        print(full_sentence)\n",
    "        print('')\n",
    "        print('')\n",
    "    if generated > num_to_print:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
