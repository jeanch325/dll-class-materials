{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markovify in /Users/maxfowler/opt/anaconda3/lib/python3.7/site-packages (0.8.2)\r\n",
      "Requirement already satisfied: unidecode in /Users/maxfowler/opt/anaconda3/lib/python3.7/site-packages (from markovify) (1.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "# installing markovify\n",
    "!pip install markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ completed\n"
     ]
    }
   ],
   "source": [
    "# example of text cleaning\n",
    "import json\n",
    "tweets_json_path = '/Users/maxfowler/computer/projects/project-archive/2017/computer-lab-publication/versacejs.json'\n",
    "texts = []\n",
    "with open(tweets_json_path) as f:\n",
    "    contents = json.loads(f.read())\n",
    "    for tweet in contents:\n",
    "        texts.append(tweet['text'])\n",
    "        \n",
    "output_path = \"/Users/maxfowler/Desktop/tweetcorpus.txt\"\n",
    "with open(output_path, 'w') as f:\n",
    "    for text in texts:\n",
    "        f.write(text + '\\n')\n",
    "        \n",
    "print('++ completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of text cleaning\n",
    "import json\n",
    "maildir = '/Users/maxfowler/Desktop/maildir'\n",
    "\n",
    "import re\n",
    "\n",
    "lines = []\n",
    "\n",
    "import os\n",
    "dirs  = os.listdir(maildir)\n",
    "for d in dirs:\n",
    "    dirpath = os.path.join(maildir, d)\n",
    "    emails_path = os.path.join(dirpath, '_sent_mail')\n",
    "    if os.path.exists(emails_path):\n",
    "        emails = os.listdir(emails_path)\n",
    "        for email in emails[:1]:\n",
    "            email_path = os.path.join(emails_path, email)\n",
    "#             print(email_path)\n",
    "            with open(email_path) as f:\n",
    "                contents = f.read()\n",
    "                parts = re.split(r\"Subject:.*\\n\", contents)\n",
    "                email_content = parts[-1]\n",
    "                for line in email_content.split('\\n'):\n",
    "                    if not ':' in line:\n",
    "                        lines.append(line)\n",
    "#                         print(line)\n",
    "                        \n",
    "output_path = '/Users/maxfowler/Desktop/texts/enron.txt'\n",
    "with open(output_path, 'w') as f:\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            f.write(line + '\\n')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "also me: hillary is a wilderness of mirrors\n",
      "staying alive out of a revolving door\n"
     ]
    }
   ],
   "source": [
    "# simple markov\n",
    "import markovify\n",
    "\n",
    "\n",
    "class NewlineText(markovify.Text):\n",
    "    def sentence_split(self, text):\n",
    "        return re.split(r\"\\s*\\n\\s*\", text)\n",
    "\n",
    "# Get raw text as string.\n",
    "with open(\"/Users/maxfowler/Desktop/texts/versace.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Build the model.\n",
    "text_model = markovify.NewlineText(text)\n",
    "    \n",
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    sentence = text_model.make_sentence()\n",
    "    if not \"@\" in sentence:\n",
    "        print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penguin had gone, and the skuas. The\n",
      "penguin attempted to build its nest in the spring, in the little prawn-like euphausia\n",
      "penguin to get food during the following pages.\n",
      "penguin would be seen that the little creatures seemed much out\n",
      "penguin is the maternal instinct\n"
     ]
    }
   ],
   "source": [
    "# with_start\n",
    "import markovify\n",
    "\n",
    "\n",
    "class NewlineText(markovify.Text):\n",
    "    def sentence_split(self, text):\n",
    "        return re.split(r\"\\s*\\n\\s*\", text)\n",
    "\n",
    "# Get raw text as string.\n",
    "with open(\"/Users/maxfowler/Desktop/texts/antarctic-penguins.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Build the model.\n",
    "text_model = markovify.NewlineText(text)\n",
    "    \n",
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    sentence = text_model.make_sentence_with_start(beginning=\"penguin\", strict=False)\n",
    "    if not \"@\" in sentence:\n",
    "        print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reservoirs that supply the three empty abodes to which\n",
      "the air, but by software error sits permanently untouched is a sponsored post for L'Oreal\n",
      "anyway, and there were many of the sparrows. Instead of the place itself, you learn that it was\n",
      "disabling the trackpad worked for 2 minutes and draw a map of where you live\n",
      "with many birds, especially the mountain bluebird.\n"
     ]
    }
   ],
   "source": [
    "# combining models\n",
    "import markovify\n",
    "\n",
    "\n",
    "class NewlineText(markovify.Text):\n",
    "    def sentence_split(self, text):\n",
    "        return re.split(r\"\\s*\\n\\s*\", text)\n",
    "\n",
    "patha = \"/Users/maxfowler/Desktop/texts/notplants.txt\"\n",
    "pathb = \"/Users/maxfowler/Desktop/texts/versace.txt\"\n",
    "pathb = \"/Users/maxfowler/Desktop/texts/birds-of-rockies.txt\"\n",
    "\n",
    "with open(patha) as fa:\n",
    "    text_a = fa.read()\n",
    "    \n",
    "with open(pathb) as fb:\n",
    "    text_b = fb.read()\n",
    "\n",
    "# Build the model.\n",
    "model_a = markovify.NewlineText(text_a)\n",
    "model_b = markovify.NewlineText(text_b)\n",
    "\n",
    "\n",
    "model_combo = markovify.combine([ model_a, model_b ], [ 1, 0.2 ])\n",
    "    \n",
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    sentence = model_combo.make_sentence()\n",
    "    if not \"@\" in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional advice on securing IIS web servers. In addition, it includes a year to | to climb the heights without any hesitation, threading their way past the rookery. As the thaw came later in\n",
      "\n",
      "\n",
      "We need to tell him. Also, what do you do discover any other compromised servers please make backups of all my Bid Week transactions. Let me know if you would | would swoop at the lumps of blubber as we lay in batches some hundreds of\n",
      "\n",
      "\n",
      "hear that the company should | should a chick go astray it stands a good six knots,\n",
      "\n",
      "\n",
      "additional information about this vulnerability, but two EBS servers that are successfully compromised exhibit the | the sea. Parties of penguins arrived at the material beneath her, shooting out\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# concatenating\n",
    "import markovify\n",
    "\n",
    "\n",
    "class NewlineText(markovify.Text):\n",
    "    def sentence_split(self, text):\n",
    "        return re.split(r\"\\s*\\n\\s*\", text)\n",
    "\n",
    "patha = \"/Users/maxfowler/Desktop/texts/enron.txt\"\n",
    "pathb = \"/Users/maxfowler/Desktop/texts/antarctic-penguins.txt\"\n",
    "\n",
    "with open(patha) as fa:\n",
    "    text_a = fa.read()\n",
    "    \n",
    "with open(pathb) as fb:\n",
    "    text_b = fb.read()\n",
    "\n",
    "# Build the model.\n",
    "model_a = markovify.NewlineText(text_a)\n",
    "model_b = markovify.NewlineText(text_b)\n",
    "    \n",
    "generated = 0\n",
    "# Print five randomly-generated sentences\n",
    "for i in range(100):\n",
    "    sentence_a = model_a.make_sentence()\n",
    "    if not sentence_a:\n",
    "        continue\n",
    "    a_words = sentence_a.split(' ')\n",
    "    sentence_b = model_b.make_sentence_with_start(beginning=a_words[-1], strict=False)\n",
    "    if sentence_a and sentence_b:\n",
    "        generated += 1\n",
    "        full_sentence = sentence_a + ' | ' + sentence_b\n",
    "        print(full_sentence)\n",
    "        print('')\n",
    "        print('')\n",
    "    if generated > 3:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "for complete documentation on random and string methods:\n",
    "- https://docs.python.org/3/library/random.html\n",
    "- https://docs.python.org/2.5/lib/string-methods.html\n",
    "\n",
    "^ there will be lots of methods here you probably won't use often, but it can be helpful for seeing what's available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
